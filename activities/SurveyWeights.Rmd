---
title: "SurveyWeights"
output: html_document
---

---
title: "HW11: Education Level and Survey Weighting"
author: "Quinn Muller"
---

```{r setup, include=FALSE}
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

# Introduction

In this assignment, you'll examine how survey weighting affects our understanding of voting intentions across different education levels, using the data we examined in class. You'll calculate both weighted and unweighted statistics, create visualizations, and reflect on the implications for reporting.

## The Data

The nonvoters dataset contains survey responses about voting intentions and behaviors from a national survey. The survey was conducted prior to an election and includes demographic information like education level.

```{r}
# Load the dataset
nonvoters_data <- read_csv("https://raw.githubusercontent.com/dwillis/jour405_files/refs/heads/main/nonvoters_data.csv")

# Take a quick look at the data structure
glimpse(nonvoters_data)
```

### Key Variables

- `weight`: Survey weight assigned to each respondent
- `Q21`: Voting intention (1 = Yes, 2 = No, 3 = Unsure/Undecided)
- `educ`: Education level (College, Some college, High school or less)

## Task 1: Education Distribution

First, let's examine the distribution of education levels in our sample. Replace "REPLACE_ME" with the correct variable for education level.

```{r}

education_distribution <- nonvoters_data |>
  count(educ) |>
  mutate(percentage = n / sum(n) * 100) |>
  kable(digits = 1, col.names = c("Education Level", "Count", "Percentage (%)"))

education_distribution
```

## Task 2: Reflection Question

Why might education levels in survey samples often differ from the general population? What factors might cause certain education groups to be over or underrepresented?

First off, a lot of surveys are offered to and completed by college students. Also, higher educated individuals may have more time to complete surveys or be more compelled to participate in efforts that support our democracy or reporting. The ability to get in contact with individuals might also cause certain education groups to be over or under represented. People with less education may have less money and time and may not answer their phones or have time to scroll the internet to find these surveys, leading them to be underrepresented.

## Task 3: Unweighted Analysis by Education

Now, let's calculate unweighted voting intentions by education level. This is what we would report if we didn't apply any weighting to our sample.

```{r}
# Calculate unweighted voting intentions by education
unweighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Count responses
  summarize(count = n(), .groups = "drop_last") |>
  # Calculate percentages
  mutate(total = sum(count),
         percentage = count / total * 100) |>
  ungroup()

# Create a more readable format with voting intentions as columns
unweighted_educ_summary <- unweighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(unweighted_educ_summary, digits = 1, caption = "Unweighted Voting Intentions by Education Level")
```

## Task 4: Reflection Question

Based just on this unweighted analysis, what headline might you write for a news story about education and voting intentions?

Intent to vote increases with level of education

## Task 5: Weighted Analysis by Education

Next, let's apply survey weights to see how this changes our results. Instead of just counting responses, we'll sum the weights for each group. Replace "REPLACE_ME" with the appropriate weight variable

```{r weighted-by-education}

weighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Sum the weights instead of counting
  summarize(weighted_count = sum(weight), .groups = "drop_last") |>
  # Calculate weighted percentages
  mutate(weighted_total = sum(weighted_count),
         weighted_percentage = weighted_count / weighted_total * 100) |>
  ungroup()

# Create a more readable format
weighted_educ_summary <- weighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = weighted_percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(weighted_educ_summary, digits = 1, caption = "Weighted Voting Intentions by Education Level")
```

## Task 6: Reflection Questions

1. How did the percentages change after applying weights? Which education group showed the biggest changes?

The percentages didn't change much for college graduates but they did change by a couple percentage points for people who selected "High School or less"--which was the most drastic change. The change for people who completed som ecolelge fell somewhere in the middle.

2. Why might the weighted results be considered more accurate than the unweighted results?

They might be considered more accurate because they account for unintentional misrepresentation through random sampling. In this case, they account for less "High School or less" respondents.

## Task 7: Comparison of Weighted vs. Unweighted Results

Let's create a direct comparison table to see the differences more clearly.

```{r}

comparison <- unweighted_educ_summary |>
  inner_join(weighted_educ_summary, by = "educ", suffix = c("_unweighted", "_weighted")) |>
  mutate(
    # Calculate the differences between weighted and unweighted percentages
    yes_diff = `Yes (%)_weighted` - `Yes (%)_unweighted`,
    no_diff = `No (%)_weighted` - `No (%)_unweighted`,
    unsure_diff = `Unsure (%)_weighted` - `Unsure (%)_unweighted`
  ) |>
  # Select just the columns we want to display
  select(educ, yes_diff, no_diff, unsure_diff) |>
  rename(
    "Education Level" = educ,
    "Yes (% point diff)" = yes_diff,
    "No (% point diff)" = no_diff,
    "Unsure (% point diff)" = unsure_diff
  )

kable(comparison, digits = 1, caption = "Difference Between Weighted and Unweighted Results (percentage points)")
```

## Task 8: Reflection Question

Which education group shows the largest differences between weighted and unweighted results?

High school or less

## Task 9: Visualization

Visualizations can help us see the differences more clearly. Let's create a bar chart comparing weighted and unweighted "Yes" responses by education level. Replace "REPLACE_ME" with the correct variable name

```{r}
educ_viz_data <- bind_rows(
  # Unweighted data
  unweighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses (Q21=1)
    mutate(Type = "Unweighted") |>
    select(Type, educ, percentage),
  
  # Weighted data - 
  weighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses
    mutate(
      Type = "Weighted",
      percentage = c(93.484409, 70.774705, 85.051096)
    ) |>
    select(Type, educ, percentage)
)

# Create a grouped bar chart
ggplot(educ_viz_data, 
       aes(x = educ, y = percentage, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), 
            position = position_dodge(width = 0.9), vjust = -0.5) +
  labs(
    title = "Weighted vs. Unweighted 'Yes' Responses by Education",
    subtitle = "Q21: Do you plan to vote in the November election?",
    y = "Percentage (%)",
    x = "Education Level"
  ) +
  scale_fill_manual(values = c("Unweighted" = "pink", "Weighted" = "hotpink")) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )
```

## Task 10: Reflection Questions

Does the visualization make it easier to see the differences between weighted and unweighted results? Why or why not?

Yes. Since the numbers are translated into bars that are right next to each other, you can see the physical difference between the weighted and unweighted results.

## Task 11: Summary

Based on your analysis of weighted and unweighted results by education level, write a brief (2-3 paragraph) journalistic summary of what you found. You should try to address:

1. How education level relates to voting intentions
2. How weighting affected your understanding of this relationship
3. What this means for interpreting polling results in news reporting

The intent to vote is definitely correlated with a higher educational background. Voters who graduated from college were the most likely to vote with 93% of college-educated voter intending to do so. On the other hand, voters who graduated from high school or less were the least likely to vote--weighted or unweighted for educational background--with only 71% (weighted) intending to vote. 

Weighting impacts the significance of certain votes and after comparing the weighted and unweighted values, there wasn't too much of a change except pertaining to voters with an educational background of high school or less. Regardless, the trend is still the same, with voters with more educational experience being significantly more likely to vote. This goes to show that sometimes weighting can have a meaningful impact on the numbers, as it did with the high school or less voters. However, sometimes weighting can have little to no impact on the numbers, as it did with voters with any level of college education.

## Task 12: Final Reflection Questions

1. Why is it important for journalists to understand survey weighting when reporting on polls?

It's always important for journalists to understand the methodology that goes into the polls that they are reporting. Weighting also may have a significant difference on the outcome of the story told by the statistics.

2. How might the differences between weighted and unweighted results affect how you would report on this data?

If there is a significant difference between the two results that just may be a story in itself, whether it's about the inaccuracy of the poll's sample, or like the Post article we read. This could lead to a completely different story like that about people not answering via certain communications methods or how certain demographic groups are underrepresented in polls. Aside from that, the difference in the results could potentially change the entire story by closing a gap that isn't so wide anymore or by making a statistic more noteworthy.

3. What additional information would you want to know about how the weights were calculated before using this data in a news story?

I'd want to know if the data was already weighted by the other demographic factors that they provided like race, gender, and income. I'd also want to know if any of those weights made a significant difference in the data. Knowing why certain responses were weighted is important as well because that could provide some insight into which groups are being over- or underrepresented.
